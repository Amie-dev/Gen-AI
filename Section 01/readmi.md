# Introduction

Welcome to **Production-grade AI Agents with LangChain.js, LangGraph.js, RAG, Next.js, LangSmith & Real JS/TS Projects**.  
This course is designed for **JavaScript and TypeScript engineers** who want to build **real, shippable agentic systems**. Unlike Python-first tutorials, this program focuses entirely on the JS/TS ecosystem, ensuring you can integrate AI agents directly into modern web applications.

---

# Course Prerequisites

Before starting, you should be comfortable with:

- **JavaScript/TypeScript fundamentals**: ES6+, async/await, modules.
- **Node.js basics**: npm/yarn, environment variables, package management.
- **Frontend development**: Familiarity with React or Next.js.
- **APIs & REST/GraphQL**: Understanding how to consume and build APIs.
- **Basic AI/ML concepts**: What LLMs are, embeddings, and vector databases (no deep ML math required).

Optional but helpful:

- Experience with **Docker** or cloud deployment.
- Familiarity with **Git/GitHub workflows**.

---

# What This Course Is Not

To set expectations clearly:

- ❌ This is **not** a Python-first LangChain course.  
- ❌ This is **not** a purely theoretical AI/ML class.  
- ❌ This is **not** a toy-demo showcase.  
- ❌ This is **not** focused on training your own models from scratch.  

Instead, it’s about **building production-ready agentic systems in JS/TS** using existing LLMs and frameworks.

---

# How to Follow This Course

1. **Clone the starter repo**: Each module has a scaffolded project.
2. **Follow modules sequentially**: Concepts build on each other.
3. **Hands-on coding**: Every lesson includes a real project you’ll ship.
4. **Experiment**: Modify examples, extend agents, and deploy them.
5. **Use LangSmith**: Trace, debug, and monitor your agents as you go.
6. **Deploy with Next.js**: By the end, you’ll have a full-stack AI app running locally or in the cloud.

---

# Resources to Follow

- **LangChain.js Docs** → [https://js.langchain.com](https://js.langchain.com)  
- **LangGraph.js Docs** → [https://js.langchain.com/docs/langgraph](https://js.langchain.com/docs/langgraph)  
- **LangSmith** → [https://smith.langchain.com](https://smith.langchain.com)  
- **Next.js Docs** → [https://nextjs.org/docs](https://nextjs.org/docs)  
- **Vector Databases** (e.g., Pinecone, Weaviate, Supabase pgvector)  
- **OpenAI API** → [https://platform.openai.com](https://platform.openai.com)  
- **Anthropic Claude API** → [https://www.anthropic.com](https://www.anthropic.com)  
- **Free models**: Hugging Face Hub, Ollama, OpenRouter.

---

# ⚡ Important: Which Models to Use — Paid or Free?

Choosing the right LLM is critical:

- **Paid Models (Recommended for Production)**  
  - **OpenAI GPT-4.1/GPT-4 Turbo**: Best balance of quality and speed.  
  - **Anthropic Claude 3.5**: Strong reasoning and safety.  
  - **Cohere Command R+**: Optimized for RAG pipelines.  

- **Free/Open Models (Great for Prototyping)**  
  - **LLaMA 3 (Meta)**: Available via Hugging Face or Ollama.  
  - **Mistral 7B**: Lightweight, efficient, strong for local use.  
  - **Gemma (Google)**: Open-source, tuned for reasoning.  

### Guidance:

- Start with **free models** locally (Ollama, Hugging Face) for experimentation.  
- Move to **paid APIs** (OpenAI, Anthropic, Cohere) when you need **production reliability, scalability, and better performance**.  
- Use **LangSmith** to benchmark different models against your tasks before committing.  

---

> ✅ By the end of this course, you’ll know how to **prototype with free models** and **ship with paid ones** depending on your project’s needs.
