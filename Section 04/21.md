
# **21. Sampling Knobs: Temperature, Top-p, Max Tokens & Determinism**

> Sampling knobs control **how the LLM chooses the next token**.
> They directly affect **creativity, reliability, cost, and agent safety**.

---

## **21.1 Why Sampling Knobs Matter**

LLMs predict **probabilities** for the next token.

Sampling knobs decide:

* How random the choice is
* How safe or creative the output is
* Whether output is repeatable
* Whether JSON stays valid

üëâ **Critical for agents & production systems**

---

## **21.2 Temperature üåë‚Üíüî• (Randomness Control)**

### Definition

**Temperature** controls how much randomness is applied to token selection.

---

### How It Works

* Low temperature ‚Üí choose most probable token
* High temperature ‚Üí allow less probable tokens

---

### Temperature Scale

| Temperature | Behavior            |
| ----------- | ------------------- |
| `0.0`       | Fully deterministic |
| `0.2‚Äì0.3`   | Very stable         |
| `0.5‚Äì0.7`   | Balanced            |
| `0.9+`      | Highly creative     |

---

### Example

Prompt: *‚ÄúGive one color‚Äù*

* **Temp = 0.0** ‚Üí `Blue` (same every time)
* **Temp = 0.9** ‚Üí `Turquoise`, `Crimson`, `Indigo`

---

### Agent Rule ‚≠ê

> **Use LOW temperature (0‚Äì0.3) for JSON & tool calling**

---

## **21.3 Top-p (Nucleus Sampling)**

### Definition

**Top-p** limits token choices to a **probability mass**.

Instead of choosing from *all tokens*:

* Model chooses from **smallest set whose total probability ‚â• p**

---

### Example

If tokens have probabilities:

```
A: 0.5
B: 0.3
C: 0.15
D: 0.05
```

* `top_p = 0.8` ‚Üí {A, B}
* `top_p = 0.95` ‚Üí {A, B, C}

---

### Top-p Scale

| top_p     | Behavior       |
| --------- | -------------- |
| `0.1‚Äì0.3` | Very strict    |
| `0.8‚Äì0.9` | Balanced       |
| `1.0`     | No restriction |

---

### Temperature vs Top-p

| Temperature               | Top-p                   |
| ------------------------- | ----------------------- |
| Controls randomness       | Controls candidate pool |
| Affects probability shape | Cuts tail tokens        |

üëâ Usually **use one**, not both aggressively

---

## **21.4 Max Tokens (Output Length Control)**

### Definition

**max_tokens** limits **how many tokens the model can generate**.

---

### Why It Matters

* Prevents runaway costs
* Protects context window
* Avoids incomplete JSON

---

### Example

```json
{
  "max_tokens": 300
}
```

‚ö†Ô∏è If max_tokens is too small:

* JSON gets cut
* Agent fails ‚ùå

---

### Agent Best Practice

> Always leave **buffer tokens** for closing braces in JSON.

---

## **21.5 Determinism (Repeatability üîÅ)**

### Definition

**Determinism** means:

> Same input ‚Üí same output every time

---

### How to Achieve Determinism

| Setting     | Value           |
| ----------- | --------------- |
| Temperature | `0.0`           |
| Top-p       | `1.0` or unused |
| Prompt      | Fixed           |
| Tools       | Stable          |

---

### Why Determinism Matters for Agents

* Reliable tool calling
* Predictable workflows
* Debugging & testing
* Production safety

---

### Non-Deterministic Output Problems

‚ùå Different tool chosen
‚ùå JSON field missing
‚ùå Schema violations

---

## **21.6 Knob Combinations (Important Table ‚≠ê)**

| Use Case         | Temp    | Top-p | Max Tokens |
| ---------------- | ------- | ----- | ---------- |
| Tool calling     | 0.0‚Äì0.2 | 1.0   | Low        |
| JSON output      | 0.0     | 1.0   | Exact      |
| Chat assistant   | 0.5‚Äì0.7 | 0.9   | Medium     |
| Creative writing | 0.9     | 0.95  | High       |

---

## **21.7 Sampling Knobs in JSON-First Systems**

### Key Rules

* Low randomness
* Strict schemas
* Limited output size
* Retry on invalid JSON

---

### Example Safe Agent Config

```json
{
  "temperature": 0.1,
  "top_p": 1.0,
  "max_tokens": 400
}
```

---

## **21.8 Exam-Focused Q&A ‚≠ê**

**Q1:** What does temperature control?
**Ans:** Randomness in token selection.

**Q2:** What is top-p sampling?
**Ans:** Selecting tokens from a probability-limited subset.

**Q3:** How do you ensure deterministic output?
**Ans:** Temperature = 0, fixed prompt, stable tools.

**Q4:** Why is low temperature preferred for agents?
**Ans:** To ensure reliable JSON and tool calls.

---

## **21.9 Common Mistakes ‚ö†Ô∏è**

* High temperature + JSON ‚ùå
* Low max_tokens causing cut JSON ‚ùå
* Using both high temp and low top-p ‚ùå
* Expecting creativity from deterministic setup ‚ùå

---

## **21.10 Section 21 Summary**

* Sampling knobs control randomness & reliability
* Temperature affects creativity
* Top-p limits token choices
* max_tokens controls output length & cost
* Determinism is essential for agents

---
